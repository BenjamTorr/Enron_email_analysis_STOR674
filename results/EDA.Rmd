---
title: "Explore_data"
author: "Yang Xiang and Benjamin Torres"
date: "2024-11-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Enron data set initial exploration

In this document we explore the dataset. This datasets contains emails from the extinctict company Enron. Our first goal is the obtain the information from the folders once downloaded the data.

We will start by loading some files and the dataset

```{r}
rm(list=ls())

source("D:/UNC/PhD UNC/Second Year/STOR 674/Project/git/Enron_email_analysis_STOR674/scripts/R scripts/data_utils.R")
setwd("D:/UNC/PhD UNC/Second Year/STOR 674/Project/git/Enron_email_analysis_STOR674/enron_mail_20150507")
emails.all.files <- list.files("./maildir/", full.names = T, recursive = T)
paste("The number of emails in this dataset: ", length(emails.all.files))
```

We can see that our functions passed the tests and that we have a huge amount of emails!
Now lets try to understand what is in this emails. We will use a predefined function (see data_utils.R for extra information) Lets see only the first 10 for computational convenience.

```{r}
set.seed(123) # seed for reproducibility
email_data = parse_all_emails(emails.all.files) # this may take some time
email_data$Sender[1:10]
```
AS we see, not all of the emails are internal emails, there are people outside of enron getting email. For the purpose of this analysis, we will eliminate those and only stay with the receivers that are within enron.

```{r}
sender_enron <- email_data$Sender[grepl("@enron.com", email_data$Sender)]
receiver <- split_receivers(email_data)$Receiver # expand table for multiple receivers(see data_utils.R)
receiver_enron <- receiver[grepl("@enron.com", receiver)] #get only enron emails

receiver_enron
```

Now, we want to see how many unique users we have within enron.

```{r}
# The number of unique users in the company
paste("The number of unique users in the company ", nrow(data.frame(item = c(sender_enron,receiver_enron)) %>%
       count(item, name = "frequency")))
```
## Descriptive analysis 

Now, we move to a more graphical way to present the information. The first point we explore is the frequency of sent emails. Most people only send a small amount emails.

```{r}
# Plot figures to show the total number of emails sending and receiving by each employee in this company. 
df_from <- data.frame(item = sender_enron) %>%
  count(item, name = "frequency")
ggplot(df_from, aes(x = frequency)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Histogram of Item Frequencies", x = "Number of Sent Emails", y = "Count") +
  theme_minimal()
```
Now, who are the people who sent the most emails and receive the most emails? We make some table operations to get this information.

```{r}
df_to <- data.frame(item = receiver_enron) %>%
  count(item, name = "frequency")
ggplot(df_to, aes(x = frequency)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Histogram of Item Frequencies", x = "Number of Received Emails", y = "Count") +
  theme_minimal()

# show top 10 people who sent the most emails
df_from[order(df_from[,2],decreasing = TRUE)[1:10],]
# show top 10 people who got the most emails
df_to[order(df_to[,2],decreasing = TRUE)[1:10],]
```
If we notice, a bunch of users just sent a couple emails and did not interect further. For the analysis this users may not be that useful. In the cell below we explore how many active users (2 or more email sent and received) are in enron.

```{r}
# All users in the company
all_users <- data.frame(item = c(sender_enron, receiver_enron)) %>%
  count(item, name = "frequency")
all_users <- all_users[,1]

# Remove inactive users (keep users that at least send 2 emails and receive 2 emails)
n <- length(all_users)
active_users <- NULL
for (i in 1:n){
  if (length(which(df_from == all_users[i])) > 0){
    if (length(which(df_to == all_users[i])) > 0){
      if ((df_from[which(df_from == all_users[i]),][2] > 1) & (df_to[which(df_to == all_users[i]),][2] > 1)){
        active_users <- c(active_users, all_users[i])
      }
      
    }
  }
}
paste("The number of active users in the company", length(active_users))

```
Next, we visualize the interaction between active users in the company. Note that the isolate nodes indicate they only interact with inactive users or themselves.

```{r}
## Get edges between users
edges = NULL
u=0
for (i in 1:length(emails.all.files)){
  if(u==1){
    break
  }
  index_from_users <- which(active_users == email_data$Sender[i])
  to_list <- split_receivers(email_data[i,])$Receiver
  if ((length(to_list) >0) & (length(index_from_users) > 0)){
    for (j in 1:length(to_list)){
      index_to_users <- which(active_users == to_list[j])
      if(length(index_to_users) > 0){
        edges <- c(edges, index_from_users, index_to_users)
      }
      if(length(edges) %% 2 == 1){
        print(i)
        u=1
        break
      }
    }
  }
}

# Use igraph to do the visualization
library("igraph")
g <- make_graph(edges,  n=length(active_users), directed = FALSE)
par(mar = c(1,1,1,1))
png("interaction_of_active_users.png") 
plot(g, vertex.size = 5, vertex.label = NA, edge.width=0.1, asp=0.9)
dev.off()

```
We use word2vec to train an embedding and use it to do further analysis.

```{r}
library(word2vec)
# Transfer all the words to lower cases
email_all_content <- tolower(email_data$Content)

set.seed(123)
# Train a word2vec model
model <- word2vec(email_all_content[1:200000], type = "cbow", dim=1000)
embedding <- as.matrix(model)
dim(embedding)

# Print the model
write.word2vec(model, "./myword2vecmodel.bin")

```

Now we consider using the embeddings to do email folder prediction for each person

```{r}
# Load the pretrained word2vec model
library(word2vec)
model     <- read.word2vec("/Users/yangxiang/Documents/FinalProject674/GoogleNews-vectors-negative300.bin")
embedding <- as.matrix(model)

# A function that takes person name and model as input and output the classification result
folder_classification <- function(model, email_data, user_name){
  # Extract data information of this person
  email_person_data <- email_data[which(email_data$User==user_name),]
  email_person_labels <- email_data$Folder[which(email_data$User==user_name)]
  
  # Get rid of the folders with less emails
  labels <- levels(factor(email_person_labels))
  for (i in 1:length(labels)){
    if (length(which(email_person_labels==labels[i]))<50){
      email_person_data <- email_person_data[-which(email_person_data$Folder == labels[i]),] 
    }
  }
  
  # Get rid of all_documents folder as there is no clear pattern inside
  email_person_data <- email_person_data[-which(email_person_data$Folder == "all_documents"),]
  
  # Merge the folders of sent and merge the folders of inbox
  subset_sent <- grep("sent", email_person_data$Folder, ignore.case = TRUE)
  if (length(subset_sent) > 0){
    email_person_data[subset_sent,]$Folder <- "sent"
  }
  subset_inbox <- grep("inbox", email_person_data$Folder, ignore.case = TRUE)
  if (length(subset_inbox) > 0){
    email_person_data[subset_inbox,]$Folder <- "inbox"
  }
  
  # Transform the folder name to factors and use them as labels
  email_person_labels <- factor(email_person_data$Folder)
  
  n <- length(email_person_labels)
  email_person_data$Content <- tolower(email_person_data$Content)
  
  # For each email, do embedding for each word and take the average as the embedding of this email
  email_person_embbedding <- matrix(0,n,model$dim)
  for (i in 1:n){
    words <- str_extract_all(email_person_data$Content[i], "\\b\\w+\\b")[[1]]
    words_embeddings <- predict(model, newdata = words, type = "embedding")
    words_embeddings[is.na(words_embeddings)] <- 0
    if(sum(is.na(words_embeddings))>0){
      break
    }
    if(!is.null(dim(words_embeddings))){
      email_person_embbedding[i,] <- colMeans(words_embeddings)
    }else{
      email_person_embbedding[i,] <- words_embeddings
    }
  }
  
  library(caret)
  library(randomForest)
  
  # Set seed for reproduction
  set.seed(123)
  
  n_sample = length(email_person_labels)
  
  # Split train and test sets
  trainIndex <- createDataPartition(email_person_labels, p = 0.8, list = FALSE)
  train_data <- email_person_embbedding[trainIndex,]
  train_labels <- email_person_labels[trainIndex]
  test_data <- email_person_embbedding[-trainIndex, ]
  test_labels <- email_person_labels[-trainIndex]
  
  # Train a Random Forest classifier
  model_rf <- randomForest(x = train_data, y = train_labels)
  
  # Print model summary
  print(model_rf)
  
  # Predict on test data
  predictions <- predict(model_rf, test_data)
  
  # Evaluate model performance
  conf_matrix <- confusionMatrix(predictions, test_labels)
  print(conf_matrix)

}

# Try the classification on one person's folders
user_name <- "weldon-c"
folder_classification(model,email_data,user_name)
```


